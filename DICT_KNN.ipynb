{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e7e2f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "###Loading packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_curve\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4538f684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measurements(y_test, y_pred, y_pred_prob):  \n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    sensitivity = metrics.recall_score(y_test, y_pred)\n",
    "    TN, FP, FN, TP = confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity = TN/(TN+FP)\n",
    "    precision = metrics.precision_score(y_test, y_pred)\n",
    "    f1 = metrics.f1_score(y_test, y_pred)\n",
    "    mcc = metrics.matthews_corrcoef(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_prob)\n",
    "    npv = TN/(TN+FN)       \n",
    "    return [TN, FP, FN, TP, acc, auc, sensitivity, specificity, precision, npv, f1, mcc]\n",
    "\n",
    "def model_predict(X, y, y_index, model, col_name):\n",
    "    y_pred_prob = model.predict_proba(X)\n",
    "    # keep probabilities for the positive outcome only\n",
    "    y_pred_prob = y_pred_prob[:, 1]\n",
    "    y_pred_class = np.where(y_pred_prob > 0.5, 1, 0)\n",
    "\n",
    "    ###create dataframe\n",
    "    pred_result = pd.DataFrame()\n",
    "    pred_result['id'] = y_index\n",
    "    pred_result['y_true'] = y\n",
    "    pred_result['prob_'+col_name] = y_pred_prob\n",
    "    pred_result['class_'+col_name] = y_pred_class\n",
    "    \n",
    "    performance =measurements(y, y_pred_class, y_pred_prob)\n",
    "\n",
    "    return pred_result, performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "66209674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1006, 790)\n",
      "(928, 778)\n",
      "(928, 636)\n",
      "X_train shape: (742, 635)\n",
      "X_test shape: (186, 635)\n",
      "y_train shape: (742,)\n",
      "y_test shape: (186,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DICT= pd.read_excel(r'C:/Users/Yanyan.Qu/Desktop/Yanyan/Cardiotoxicity/DICTrank/mold2/DICTrank_Mold2_1006.xlsx')\n",
    "## remove the \"Ambiguous-DICT concern\" drugs\n",
    "print(DICT.shape)\n",
    "DICT.drop(DICT[DICT['DICT']=='Ambiguous'].index,inplace=True)\n",
    "## Classify the \"Less- and Most- DICT concern \" as cardiotox positive  and label \"1\"\n",
    "## classify the \"No-DICT concern\" as cardiotox negtive and label \"0\"\n",
    "DICT.loc[DICT['DICT']==\"Less\",'DICT']=1\n",
    "DICT.loc[DICT['DICT']==\"Most\",'DICT']=1\n",
    "DICT.loc[DICT['DICT']==\"No\",'DICT']=0\n",
    "\n",
    "cols=DICT.columns[13:]\n",
    "data=DICT[['DICT',*cols]]\n",
    "print(data.shape)\n",
    "zero_cols = data.columns[(data == 0).all()]\n",
    "\n",
    "data.drop(zero_cols, axis=1, inplace=True)\n",
    "print(data.shape)\n",
    "\n",
    "X1=data.iloc[:,1:]\n",
    "y1=data[\"DICT\"]\n",
    "\n",
    "## data and split(random and stratify)\n",
    "## X, X_test, y, y_test = train_test_split(X1, y1, test_size=.2,random_state=42)\n",
    "X, X_test, y, y_test = train_test_split(X1, y1, test_size=.2,stratify=y1,random_state=42)\n",
    "print('X_train shape:', X.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_train shape:', y.shape)\n",
    "print('y_test shape:',y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f24fb0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "## label_encoder = LabelEncoder()\n",
    "## y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93600005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "106cf79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def para_selection(var, para, X, X_test, y, y_test):\n",
    "    base_path = '/Users/Yanyan.Qu/Desktop/Yanyan/Cardiotoxicity/DICTrank/result/KNN/knn'+ var\n",
    "\n",
    "    path10 = base_path + '/training_performance'\n",
    "    path20 = base_path + '/test_performance'\n",
    "\n",
    "    path1 = base_path + '/training_class'\n",
    "    path2 = base_path + '/test_class'\n",
    "\n",
    "    ###make the directory\n",
    "    os.mkdir(base_path)\n",
    "    os.mkdir(path10)\n",
    "    os.mkdir(path20)\n",
    "\n",
    "    os.mkdir(path1)\n",
    "    os.mkdir(path2)\n",
    "    \n",
    "    #initial performance dictionary\n",
    "    train_results={}\n",
    "    test_results={}\n",
    "    pred_test_df = pd.DataFrame()\n",
    "\n",
    "    for i in range(20):\n",
    "        skf = StratifiedKFold(n_splits=5, random_state=i, shuffle=True)\n",
    "        j = 0\n",
    "        for train_index, validation_index in skf.split(X,np.array(y, dtype=np.int)):\n",
    "            ###get train, validation dataset\n",
    "            X_train, X_validation = X.iloc[train_index,:], X.iloc[validation_index,:]\n",
    "            y_train, y_validation = y.iloc[train_index], y.iloc[validation_index]\n",
    "\n",
    "            ### scale the input\n",
    "            ### scale the input\n",
    "            sc = MinMaxScaler()\n",
    "            sc.fit(X_train)\n",
    "            X_train = sc.transform(X_train)\n",
    "            X_validation = sc.transform(X_validation)\n",
    "            X_test_s = sc.transform(X_test)\n",
    "\n",
    "            ### define column name\n",
    "            col_name = 'knn_'+'seed_'+str(i)+'_skf_'+str(j)+'_paras_'+var+'_K_'+str(para)\n",
    "            col_name1 = 'knn_'+'seed_'+str(i)+'_paras_'+var+'_K_'+str(para)\n",
    "            col_name2 = 'knn_'+'paras_'+var\n",
    "           \n",
    "        ## +'_K_'+str(para)\n",
    "\n",
    "            ###create classifier\n",
    "            clf = KNeighborsClassifier(n_neighbors=para)\n",
    "            clf.fit(X_train, np.array(y_train, dtype=np.int))\n",
    "\n",
    "            ### predict validation results\n",
    "            train_class, train_result=model_predict(X_validation, np.array(y_validation, dtype=np.int),y_validation.index, clf, col_name)\n",
    "            train_results[col_name]=train_result\n",
    "\n",
    "\n",
    "            ### predict test results\n",
    "            test_class, test_result=model_predict(X_test_s, np.array(y_test, dtype=np.int),y_test.index, clf, col_name)\n",
    "\n",
    "            test_results[col_name]=test_result\n",
    "\n",
    "            pred_test_df = pd.concat([pred_test_df, test_class],axis=1, sort=False)\n",
    "            j += 1\n",
    "            train_class.to_csv(path1+'/train_'+col_name+'.csv')\n",
    "\n",
    "    ###save the result of validation results\n",
    "    pd.DataFrame(data=train_results.items()).to_csv(path10+'/train_'+col_name2+'.csv')\n",
    "    pred_test_df.to_csv(path2+'/test_'+col_name2+'.csv')\n",
    "    pd.DataFrame(data=test_results.items()).to_csv(path20+'/test_'+col_name2+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1f232f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "1\n",
      "5\n",
      "2\n",
      "7\n",
      "3\n",
      "9\n",
      "4\n",
      "11\n",
      "--- 367.9961750507355 seconds ---\n"
     ]
    }
   ],
   "source": [
    "paras = [3, 5, 7, 9, 11]\n",
    "\n",
    "for var in range(len(paras)):\n",
    "    print(var)\n",
    "    para = paras[var]\n",
    "    print(para)\n",
    "    para_selection(str(var), para, X, X_test, y, y_test)\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f694670b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', '0', '1'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## data analysis\n",
    "knn0=pd.read_csv('/Users/Yanyan.Qu/Desktop/Yanyan/Cardiotoxicity/ML Model/KNN/knn0/training_performance/train_knn_paras_0_K_3.csv')\n",
    "## knn0=knn0.rename(columns={'0':'name', '1':'value'})\n",
    "\n",
    "## df= knn0['value'].astype('str')\n",
    "print(knn0.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "11468b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0                           name  \\\n",
      "0            0   knn_seed_0_skf_0_paras_0_K_3   \n",
      "1            1   knn_seed_0_skf_1_paras_0_K_3   \n",
      "2            2   knn_seed_0_skf_2_paras_0_K_3   \n",
      "3            3   knn_seed_0_skf_3_paras_0_K_3   \n",
      "4            4   knn_seed_0_skf_4_paras_0_K_3   \n",
      "..         ...                            ...   \n",
      "95          95  knn_seed_19_skf_0_paras_0_K_3   \n",
      "96          96  knn_seed_19_skf_1_paras_0_K_3   \n",
      "97          97  knn_seed_19_skf_2_paras_0_K_3   \n",
      "98          98  knn_seed_19_skf_3_paras_0_K_3   \n",
      "99          99  knn_seed_19_skf_4_paras_0_K_3   \n",
      "\n",
      "                                                value  TN   FP   FN   TP  \\\n",
      "0   [9, 31, 14, 95, 0.697986577181208, 0.586238532...   9   31   14   95   \n",
      "1   [12, 28, 10, 99, 0.7449664429530202, 0.6826834...  12   28   10   99   \n",
      "2   [12, 27, 18, 91, 0.6959459459459459, 0.6604328...  12   27   18   91   \n",
      "3   [11, 28, 13, 96, 0.722972972972973, 0.64714184...  11   28   13   96   \n",
      "4   [7, 32, 18, 91, 0.6621621621621622, 0.56563161...   7   32   18   91   \n",
      "..                                                ...  ..  ...  ...  ...   \n",
      "95  [17, 23, 10, 99, 0.7785234899328859, 0.6620412...  17   23   10   99   \n",
      "96  [5, 35, 13, 96, 0.6778523489932886, 0.55733944...   5   35   13   96   \n",
      "97  [13, 26, 15, 94, 0.722972972972973, 0.62432368...  13   26   15   94   \n",
      "98  [11, 28, 12, 97, 0.7297297297297297, 0.6841919...  11   28   12   97   \n",
      "99  [10, 29, 14, 95, 0.7094594594594594, 0.6558456...  10   29   14   95   \n",
      "\n",
      "               Accuracy                  AUC          Sensitivity  \\\n",
      "0     0.697986577181208   0.5862385321100918   0.8715596330275229   \n",
      "1    0.7449664429530202   0.6826834862385321    0.908256880733945   \n",
      "2    0.6959459459459459    0.660432839331922   0.8348623853211009   \n",
      "3     0.722972972972973   0.6471418489767113   0.8807339449541285   \n",
      "4    0.6621621621621622   0.5656316160903317   0.8348623853211009   \n",
      "..                  ...                  ...                  ...   \n",
      "95   0.7785234899328859   0.6620412844036697    0.908256880733945   \n",
      "96   0.6778523489932886   0.5573394495412844   0.8807339449541285   \n",
      "97    0.722972972972973    0.624323688543872   0.8623853211009175   \n",
      "98   0.7297297297297297   0.6841919548341566   0.8899082568807339   \n",
      "99   0.7094594594594594   0.6558456833686193   0.8715596330275229   \n",
      "\n",
      "             Specificity                  PPV                  NPV  \\\n",
      "0                  0.225    0.753968253968254    0.391304347826087   \n",
      "1                    0.3   0.7795275590551181   0.5454545454545454   \n",
      "2     0.3076923076923077   0.7711864406779662                  0.4   \n",
      "3    0.28205128205128205   0.7741935483870968   0.4583333333333333   \n",
      "4     0.1794871794871795   0.7398373983739838                 0.28   \n",
      "..                   ...                  ...                  ...   \n",
      "95                 0.425   0.8114754098360656   0.6296296296296297   \n",
      "96                 0.125    0.732824427480916   0.2777777777777778   \n",
      "97    0.3333333333333333   0.7833333333333333   0.4642857142857143   \n",
      "98   0.28205128205128205                0.776   0.4782608695652174   \n",
      "99    0.2564102564102564   0.7661290322580645   0.4166666666666667   \n",
      "\n",
      "                     F1                    MCC  \n",
      "0    0.8085106382978724     0.1184376169897682  \n",
      "1    0.8389830508474576    0.26015333820563485  \n",
      "2     0.801762114537445    0.15621597389161437  \n",
      "3    0.8240343347639485     0.1945557535148227  \n",
      "4    0.7844827586206896    0.01687181180535025  \n",
      "..                  ...                    ...  \n",
      "95   0.8571428571428572     0.3834074719255759  \n",
      "96   0.8000000000000002   0.007796952054855883  \n",
      "97   0.8209606986899564    0.22014464974713938  \n",
      "98   0.8290598290598291     0.2090994545638229  \n",
      "99    0.815450643776824    0.15294556345673924  \n",
      "\n",
      "[100 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "## cols = ['TN', 'FP', 'FN', 'TP', 'Accuracy', 'AUC', 'Sensitivity', 'Specificity', 'PPV', 'NPV', 'F1', 'MCC']\n",
    "## for i, col in enumerate(cols):\n",
    "        if i == 0:\n",
    "           knn0[col] = df.str.split(',').str[i].str.split('[').str[1].values\n",
    "        elif i == len(cols)-1:\n",
    "            knn0[col] = df.str.split(',').str[i].str.split(']').str[0].values\n",
    "        else:\n",
    "            knn0[col] = df.str.split(',').str[i].values\n",
    "        \n",
    "## print(knn0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
